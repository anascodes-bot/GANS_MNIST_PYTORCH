{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b00GdKCA9JN7"
      },
      "source": [
        "# Deep Learning with PyTorch : Build a Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  #Torch is imported for tensors operations\n",
        "torch.manual_seed(42)\n",
        "import numpy as np #Numpy for numerical computationsacc\n",
        "import matplotlib.pyplot as plt #Matplotlib for plotting\n",
        "\n",
        "from tqdm.notebook import tqdma # For showing Progress Bar"
      ],
      "metadata": {
        "id": "5DkXazDe1V-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwklBE_vlOSi"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oUWVmkulOSi"
      },
      "source": [
        "device = 'cuda' # Transfer images to gpu device\n",
        "batch_size = 128 # Size defined to be used in training loop\n",
        "noise_dim = 64  # The noise which we will give to generator\n",
        "\n",
        "epochs= 20 # How many times training loop is going to run\n",
        "\n",
        "# Hyper Parameters for Adam Optimizer\n",
        "beta_1 = 0.5\n",
        "beta_2 = 0.99\n",
        "lr = 0.0002\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thRDmRxBlOSj"
      },
      "source": [
        "# Load MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA70KkPWlOSj"
      },
      "source": [
        "from torchvision import datasets,transforms as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RPRGJDAlOSk"
      },
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "train_augs = T.Compose([\n",
        "    T.RandomRotation((-20, 20)),  # Random rotation between -20 and +20 degrees, This can help introduce variety and robustness to the training data.\n",
        "    T.ToTensor()  # Convert images to PyTorch tensors\n",
        "])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORt5m1TvlOSk"
      },
      "source": [
        "trainset=datasets.MNIST('MNIST/',download= True , train= True,transform=train_augs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN8OGFATlOSk"
      },
      "source": [
        "image,label= trainset[800] # Loading image and it's coresponding label.\n",
        "\n",
        "plt.imshow(image.squeeze(),cmap='gray') # Plot a single Image and it's squezed to remove any single dimensional array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRSk3zV1lOSl"
      },
      "source": [
        "# Load Dataset Into Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaRQzZhr7-HF"
      },
      "source": [
        "from torch.utils.data import DataLoader # It creates batches for training\n",
        "from torchvision.utils import make_grid # create a grid of images for visualization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDNysctVlOSl"
      },
      "source": [
        "trainloader= DataLoader(trainset,batch_size=batch_size,shuffle=True) # This line creates a data loader that loads training data in mini-batches. The data is shuffled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me1C0THUlOSm"
      },
      "source": [
        "print(\"The total no of batches are: \",trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader) # function is used to create an iterator from the data loader. An iterator is an object that allows you to iterate through the data loader and retrieve batches of data.\n",
        "images, _ = next(dataiter) # unction is used to get the next batch of data from the iterator\n",
        "print(images.shape)\n",
        "\n",
        "#(batch_size, channels, height, width)\n"
      ],
      "metadata": {
        "id": "J8TyKnYw1zb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R3XRbXBlOSm"
      },
      "source": [
        "# 'show_tensor_images' : function is used to plot some of images from the batch\n",
        "# The function converts the tensor to a NumPy array and creates a grid of images using make_grid, then displays it using matplotlib.\n",
        "\n",
        "def show_tensor_images(tensor_img, num_images = 16, size=(1, 28, 28)):\n",
        "    unflat_img = tensor_img.detach().cpu()\n",
        "    img_grid = make_grid(unflat_img[:num_images], nrow=4)\n",
        "    plt.imshow(img_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVLG2TA4lOSm"
      },
      "source": [
        "show_tensor_images(images,num_images = 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb1rVzijlOSn"
      },
      "source": [
        "# Create Discriminator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22qSpIBlknec"
      },
      "source": [
        "!pip install torchsummary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYvzxU2llOSn"
      },
      "source": [
        "from torch import nn # importing neural networks\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VpIDdx9lOSn"
      },
      "source": [
        "from torch.nn.modules.activation import LeakyReLU\n",
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "\n",
        "# Returns a Sequential Block\n",
        "def get_disc_block(in_channel,out_channel,kernel_size,stride):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channel,out_channel,kernel_size,stride),\n",
        "      nn.BatchNorm2d(out_channel),\n",
        "      nn.LeakyReLU(0.2)\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq_aX7EslOSo"
      },
      "source": [
        "class Discriminator(nn.Module):  # This class Discriminator is Inherited from NN MODULE\n",
        "# NN MODULE IS THE BASE CLASS OF ALL\n",
        "  def __init__(self):\n",
        "    super(Discriminator,self).__init__()  #  This line ensures that the constructor of the parent class (nn.Module) is called.\n",
        "\n",
        "    self.block1=get_disc_block(1,16,(3,3),2)\n",
        "    self.block2=get_disc_block(16,32,(5,5),2)\n",
        "    self.block3=get_disc_block(32,64,(5,5),2)\n",
        "\n",
        "    self.flatten=nn.Flatten() # flatten the output of the convolutional blocks before passing it to the linear layer.\n",
        "    self.linear=nn.Linear(in_features = 64, out_features = 1)\n",
        "\n",
        "  def forward(self,images):\n",
        "\n",
        "    x1=self.block1(images)\n",
        "    x2=self.block2(x1)\n",
        "    x3=self.block3(x2)\n",
        "\n",
        "    x4=self.flatten(x3)\n",
        "    x5=self.linear(x4)\n",
        "\n",
        "    return x5\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqZFM47slOSo"
      },
      "source": [
        "# NETWORK SUMMARY\n",
        "\n",
        "D=Discriminator()\n",
        "D.to(device)\n",
        "\n",
        "summary(D,input_size=(1,28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaSM5ky-lOSp"
      },
      "source": [
        "# Create Generator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmGinLUjlOSp"
      },
      "source": [
        "def get_gen_block(in_channels,out_channels,kernel_size,stride,final_block=False):\n",
        "  if final_block == True:\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  return nn.Sequential(\n",
        "      nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU()\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self,noise_dim):\n",
        "    super(Generator,self).__init__()   # This line ensures that the constructor of the parent class (nn.Module) is called.\n",
        "\n",
        "    self.noise_dim=noise_dim #Dimensionality of the input noise vector. This noise will be used to generate images.\n",
        "\n",
        "    self.block1=get_gen_block(noise_dim,256 ,(3,3),2)\n",
        "    self.block2=get_gen_block(256,128, (4,4),1)\n",
        "    self.block3=get_gen_block(128,64, (3,3),2)\n",
        "\n",
        "    self.block4=get_gen_block(64,1, (4,4),2,final_block=True)\n",
        "\n",
        "  def forward(self,r_noise_vec):\n",
        "\n",
        "    x=r_noise_vec.view(-1,self.noise_dim,1,1) #The input noise is reshaped to a 4D tensor with dimensions (batch_size, noise_dim, 1, 1).\n",
        "    # view operation reshapes the input noise tensor from (batch_size, noise_dim) to (batch_size, noise_dim, 1, 1)\n",
        "\n",
        "    x1=self.block1(x)\n",
        "    x2=self.block2(x1)\n",
        "    x3=self.block3(x2)\n",
        "    x4=self.block4(x3)\n",
        "\n",
        "    return x4"
      ],
      "metadata": {
        "id": "ScV9sRX4ISOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNcWK2malOSq"
      },
      "source": [
        "G=Generator(noise_dim)\n",
        "G.to(device)\n",
        "\n",
        "summary(G,input_size=(1,noise_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6v-NfQlVy8v"
      },
      "source": [
        "# Replace Random initialized weights to Normal weights\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpMoglmaUPnt"
      },
      "source": [
        "D=D.apply(weights_init)\n",
        "G=G.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLGG2YkRlOSr"
      },
      "source": [
        "# Create Loss Function and Load Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOvcqBuylOSs"
      },
      "source": [
        "def real_loss(disc_pred):\n",
        "  criterion=nn.BCEWithLogitsLoss()\n",
        "  ground_truth=torch.ones_like(disc_pred)\n",
        "  loss=criterion(disc_pred,ground_truth)\n",
        "  return loss\n",
        "\n",
        "def fake_loss(disc_pred):\n",
        "  criterion=nn.BCEWithLogitsLoss()\n",
        "  ground_truth=torch.zeros_like(disc_pred)\n",
        "  loss=criterion(disc_pred,ground_truth)\n",
        "  return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96EEpkp9lOSs"
      },
      "source": [
        "# optimizer for training the discriminator\n",
        "#D.parameters(): This passes the parameters of the discriminator model (D) to the optimizer. It allows the optimizer to update the weights and biases of the discriminator during training.\n",
        "#hese are the beta parameters used in the Adam optimizer. beta_1 and beta_2 control the exponential moving averages of gradients and squared gradients, respectively.\n",
        "D_opt=torch.optim.Adam(D.parameters(),lr=lr,betas=(beta_1,beta_2))\n",
        "G_opt=torch.optim.Adam(G.parameters(),lr=lr,betas=(beta_1,beta_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF_k10LElOSt"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmPLh41ulOSt"
      },
      "source": [
        "# This big loop goes through a set number of rounds called \"epochs\".\n",
        "#For each epoch, there are two counters: one for adding up the losses of the discriminator (a part of a computer program), and another for adding up the losses of the generator (another part of the program).\n",
        "#Inside each epoch, there's a smaller loop that looks at the training data. This data is taken in chunks, and each chunk has real pictures and their labels (like tags) that are not really used here.\n",
        "#The real pictures are moved to where they need to be processed, which can be either the main computer part (CPU) or a special powerful part (GPU).\n",
        "#Also, random noise is made using a math function. This noise is like random data that will be used to create fake pictures by another part of the program.\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "  total_d_loss = 0.0\n",
        "  total_g_loss = 0.0\n",
        "\n",
        "  for real_img, _ in trainloader:\n",
        "\n",
        "    real_img=real_img.to(device)\n",
        "    noise = torch.randn(batch_size,noise_dim,device=device)\n",
        "\n",
        "    # FIND LOSS AND UPDATE WEIGHT FOR D\n",
        "\n",
        "    D_opt.zero_grad() # Gradients are reset\n",
        "\n",
        "    fake_img=G(noise) #  generator creates fake images\n",
        "\n",
        "    D_pred=D(fake_img) # discriminator makes predictions (D_pred) on the fake images\n",
        "    D_fake_loss=fake_loss(D_pred) # fake loss is calculated using the fake_loss function.\n",
        "\n",
        "    D_pred=D(real_img) # he discriminator makes predictions on the real images\n",
        "    D_real_loss=real_loss(D_pred) #  real loss is calculated using the real_loss function.\n",
        "\n",
        "    D_loss= (D_fake_loss + D_real_loss) /2 # The final discriminator loss (D_loss) is calculated as the average of the fake and real losses.\n",
        "\n",
        "\n",
        "    total_d_loss += D_loss.item()\n",
        "\n",
        "    D_loss.backward()# The discriminator loss is backpropagated\n",
        "    D_opt.step()\n",
        "\n",
        "    # FIND LOSS AND UPDATE WEIGHT FOR G\n",
        "\n",
        "    G_opt.zero_grad()\n",
        "\n",
        "    noise= torch.randn(batch_size,noise_dim,device=device)\n",
        "\n",
        "    fake_img=G(noise)\n",
        "    D_pred= D(fake_img)\n",
        "    G_loss = real_loss (D_pred)\n",
        "\n",
        "    total_g_loss += G_loss.item()\n",
        "\n",
        "    G_loss.backward()\n",
        "    G_opt.step()\n",
        "\n",
        "avg_d_loss= total_d_loss / len(trainloader)\n",
        "avg_g_loss= total_g_loss / len(trainloader)\n",
        "\n",
        "print(\"Epoch : {} | Dloss : {} | Gloss : {}\".format(i+1,avg_d_loss,avg_g_loss))\n",
        "\n",
        "show_tensor_images(fake_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}